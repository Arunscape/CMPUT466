{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPUT 466 Final Project\n",
    "Arun Woosaree\n",
    "\n",
    "I will be doing binary classification with 3 different algorithms to detect spam in emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pipenv install\n",
    "kaggle datasets download -d uciml/sms-spam-collection-dataset\n",
    "unzip -f sms-spam-collection-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the useless columns and rename spam: 1 ham: 0\n",
    "data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis=1, inplace=True)\n",
    "data.rename(columns={\"v1\": \"label\", \"v2\": \"text\"}, inplace=True)\n",
    "data.replace({'spam': 1, 'ham': 0}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = pd.value_counts(data['label'],sort=True).sort_index()\n",
    "num.plot(kind='bar')\n",
    "plt.title('Number of Messages in Dataset')\n",
    "plt.xticks((0, 1), (\"Legitimate\", \"Spam\"), rotation=0)\n",
    "plt.ylabel('Count')\n",
    "# plt.show()\n",
    "plt.savefig(\"images/histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = TfidfVectorizer().fit_transform(data['text']).toarray()\n",
    "t = data[\"label\"]\n",
    "print(f\"Trivial classifier: all Legitimate accuracy: {accuracy_score(t, np.zeros_like(t))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, validation_curve, cross_val_score\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html?highlight=validation%20curve\n",
    "# https://www.dataquest.io/blog/learning-curves-machine-learning/\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification\n",
    "using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.get_params()\n",
    "# train_scores, valid_scores = validation_curve(LinearRegression(), X, t, param_name=\"normalize\", param_range=(True, False), n_jobs=-1)\n",
    "# plot_learning_curve(LinearRegression(), \"Linear Regression\", X, t, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import make_scorer\n",
    "accuracies = cross_val_score(lr, X, t, n_jobs=-1)\n",
    "print(accuracies)\n",
    "f\"Mean accuracy: {np.mean(accuracies)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# train_scores, valid_scores = validation_curve(LogisticRegression(), X, t, param_name=\"penalty\", param_range=('l1',), n_jobs=-1)\n",
    "# plot_learning_curve(LogisticRegression(), \"Logistic Regression\", X, t, n_jobs=-1)\n",
    "lgr = LogisticRegression()\n",
    "lgr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(lgr, X, t, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(accuracies)\n",
    "f\"Mean accuracy: {np.mean(accuracies)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n",
    "    'penalty': ('l1', 'l2', 'elasticnet', 'none'),\n",
    "}\n",
    "lg_gs = GridSearchCV(lgr, params, n_jobs=-1, verbose=4)\n",
    "lg_gs = lg_gs.fit(X, t)\n",
    "print(\"best score\", lg_gs.best_score_)\n",
    "print(\"best params\", lg_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# train_scores, valid_scores = validation_curve(MultinomialNB(), X, t, param_name=\"fit_prior\", param_range=(True,), n_jobs=-1)\n",
    "nb = MultinomialNB()\n",
    "nb.get_params()\n",
    "# plot_learning_curve(MultinomialNB(), \"Multinomial Naive Bayes\", X, t, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(nb, X, t, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(accuracies)\n",
    "f\"Mean accuracy: {np.mean(accuracies)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "p = Perceptron()\n",
    "p.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(p, X, t, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(accuracies)\n",
    "f\"Mean accuracy: {np.mean(accuracies)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty': ('l1', 'l2', 'elasticnet', 'none'),\n",
    "    'max_iter': (500, 1000, 2000)\n",
    "}\n",
    "p_gs = GridSearchCV(p, params, n_jobs=-1, verbose=4)\n",
    "p_gs = p.fit(X, t)\n",
    "print(\"best score\", p_gs.best_score_)\n",
    "print(\"best params\", p_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# train_scores, valid_scores = validation_curve(MLPClassifier(), X, t, param_name=\"solver\", param_range=('lbfgs', 'sgd', 'adam'), n_jobs=-1)\n",
    "# plot_learning_curve(MLPClassifier(), \"Multilayer Perceptron\", X, t, n_jobs=-1)\n",
    "mlp = MLPClassifier()\n",
    "mlp.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(mlp, X, t, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(accuracies)\n",
    "f\"Mean accuracy: {np.mean(accuracies)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'activation': ('relu', 'identity', 'logistic', 'tanh'),\n",
    "    'hidden_layer_sizes': ((100), (100, 50, 25), (100, 80, 60, 40, 20, 10)),\n",
    "    'learning_rate': ('invscaling', 'adaptive'),\n",
    "    'max_iter': (400, 800, 1600)\n",
    "}\n",
    "mlp_gs = GridSearchCV(mlp, params, n_jobs=-1, verbose=4)\n",
    "mlp_gs = mlp.fit(X, t)\n",
    "print(\"best score\", mlp_gs.best_score_)\n",
    "print(\"best params\", mlp_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
